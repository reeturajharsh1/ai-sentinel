.. ai_sentinel documentation master file, created by
   sphinx-quickstart on Tue Aug 12 14:53:42 2025.
   You can adapt this file completely to your liking, but it should at least
   contain the root `toctree` directive.

Welcome to AI Sentinel
======================

.. image:: https://img.shields.io/pypi/v/ai-sentinel.svg
   :target: https://pypi.org/project/ai-sentinel/
   :alt: PyPI version

.. image:: https://img.shields.io/badge/python-3.11+-blue.svg
   :target: https://www.python.org/downloads/
   :alt: Python versions

.. image:: https://img.shields.io/badge/License-MIT-yellow.svg
   :target: https://opensource.org/licenses/MIT
   :alt: License

**AI Sentinel** is a Python package designed to help developers integrate toxicity analysis 
into their applications with ease. It provides a simple, unified interface to leverage 
powerful AI models for detecting and categorizing harmful content in text.

Key Features
------------
* Easy-to-use toxicity detection API
* Support for multiple AI models
* Customizable toxicity categories
* Detailed toxicity scoring and analysis
* Async support for high-performance applications

Installation
------------
AI Sentinel can be installed from PyPI::

    pip install ai-sentinel
    or
    uv pip install ai-sentinel

Requirements
------------
* Python 3.11+

.. toctree::
    :maxdepth: 2
    :caption: Introduction

    Module Overview <overviews>

.. toctree::
    :maxdepth: 2
    :caption: Examples

    Quick Start <usage>

.. toctree::
    :maxdepth: 1
    :caption: Reference

    API Reference <api>

.. toctree::
    :maxdepth: 1
    :caption: Development

    Change Log <changelog>


